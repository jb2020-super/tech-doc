# 01｜基本概念：从参数的角度看视频图像

其实准确来说的话，不是。因为视频的压缩是一个非常复杂的过程，之后我们会有好几节课来讲视频压缩的知识。事实上，视频压缩之后的清晰度还跟压缩时选用的压缩算法，以及压缩时使用的压缩速度有关。压缩算法越先进，压缩率就会越高，码率自然就会越小。压缩速度越慢，压缩的时候压缩算法就会越精细，最后压缩率也会有提高，相同的清晰度码率也会更小。

今天我们学习了图像和视频的基础知识，都很简单但很重要，这里我为你总结了一张图帮助你记忆。

![视频图像基础](视频图像基础.webp)

总结来说，一张图像是由像素组成的，而图像有多少像素则由分辨率来表示。在分辨率之外，存取一副图像还需要特别注意 Stride 这个东西，它跟分辨率中的 Width 是不一样的。然后，一帧帧图像组成了视频，我们将每秒中的图像数量称之为帧率。视频编码后每秒的数据量称之为码率。

这些知识点是我们之后课程的基础，随着我们不断深入学习，还会不断巩固这些概念。

# 02｜YUV & RGB：原来图像是这么丰富多彩的

这里就涉及到 Color Range 这个概念。Color Range 分为两种，一种是 Full Range，一种是 Limited Range。Full Range 的 R、G、B 取值范围都是 0～255。而 Limited Range 的 R、G、B 取值范围是 16～235。

BT709 和 BT601 定义了一个 RGB 和 YUV 互转的标准规范。只有我们都按照标准来做事，那么不同厂家生产出来的产品才能对接上。BT601 是标清的标准，而 BT709 是高清的标准

图像的颜色空间主要有 RGB 和 YUV 两种。其中 RGB 图像每一个像素有 R、G、B 三个值。而 YUV 图像有３种类型，其分类如下：

1. YUV 4:4:4，一个 Y 对应一个 U 和一个 V；

2. YUV 4:2:2，左右两个 Y 对应一个 U 和一个 V；

3. YUV 4:2:0，上下左右四个 Y 对应一个 U 和一个 V。

   

同时，YUV 在存储的时候也有两种大类：一种是 Planar 格式；一种是 Packed 格式。其中 Planar 格式又分为先存 U 还是先存 V 两种。而 Packed 格式是 UV 交错存储且分为 U 在前还是 V 在前两种。

在图像采集的时候我们一般得到的原始图像是 RGB 图像，并且渲染的时候最终也是用 RGB 图像，而在编 / 解码时用的却是 YUV 图像。因此，我们需要在 RGB 和 YUV 之间互转。转换的标准有两种：一种是 BT601；一种是 BT709。

另外，在转换过程中我们还涉及到 Color Range 这个概念。Full Range 的 R、G、B 三个值的范围都是 0～255。而 Limited Range 的取值范围是 16～235。在做转换的时候我们需要选择正确的标准和 Color Range。

最后，我再一次提出了 Stride 这个概念。在读取 YUV 图像一行像素的时候一定要区分 Width 和 Stride 的区别。Width 是原始图像的宽，而 Stride 是对齐之后的一行像素使用的字节大小。这个一定要注意，千万不要弄错了。

# 03｜缩放算法：如何高质量地缩放图像？

图像缩放主要包括两个部分：一个是像素位置映射过程；一个是映射位置像素的插值过程。

### 1. 像素位置映射过程

对于分辨率为 w0 x h0 的原图像，我们需要缩放到分辨率为 w1 x h1 的目标图像。我们只需要将目标图像的每一个像素点（x，y）映射到原图像的（x * w0 / w1，y * h0 / h1）位置。一般这个映射位置不是一个整数位置。我们需要通过插值算法得到映射位置的像素值，然后将映射位置插值得到的像素值赋值给目标像素就可以了。

### 2. 映射像素的插值过程

插值过程主要会使用到插值算法。我们今天介绍了最常用的三种插值算法，分别是最近邻插值、双线性插值和双三次插值算法。三种算法的思想和优缺点如下表所示。

![插值算法](插值算法.webp)

# 04｜编码原理：视频究竟是怎么编码压缩的？

RGB 三个颜色是有相关性的，为了去掉这个相关性，减少需要编码的信息量，我们通常会把 RGB 转换成 YUV，也就是 1 个亮度分量和 2 个色度分量

视频编码主要分为熵编码、预测、DCT 变换和量化这几个步骤。

1. 熵编码（以行程编码为例）：视频编码中真正实现“压缩”的步骤，主要去除信息熵冗余。在出现连续多个 0 像素的时候压缩率会更高。
2. 帧内预测：为了提高熵编码的压缩率，先将当前编码块的相邻块像素经过帧内预测算法得到帧内预测块，再用当前编码块减去帧内预测块得到残差块，从而去掉空间冗余。
3. 帧间预测：类似于帧内预测，在已经编码完成的帧中，先通过运动搜索得到帧间预测块，再与编码块相减得到残差块，从而去除时间冗余。
4. DCT 变换和量化：将残差块变换到频域，分离高频和低频信息。由于高频信息数量多但大小相对较小，又人眼对高频信息相对不敏感，我们利用这个特点，使用 QStep 对 DCT 系数进行量化，将大部分高频信息量化为 0，达到去除视觉冗余的目的。

这里你需要注意的是，视频编码实际的步骤是预测、DCT 变换和量化，最后是熵编码。经过这几步操作之后，视频中的冗余信息大部分被去除，达到了编码压缩的效果。

# 05｜码流结构：原来你是这样的H264

为了避免错误的不断传递，就有了一种特殊的 I 帧叫 IDR 帧，也叫立即刷新帧。

我们可以看到 GOP 的大小是由 IDR 帧之间的间隔来确定的，而这个间隔我们有一个重要的概念来表示，叫做关键帧间隔

GOP 不是越大越好，也不是越小越好，需要根据实际的场景来选择。

这节课我们主要讨论了 H264 的编码层次结构和码流结构。在一个视频图像序列中，我们将其划分成一个个 GOP。GOP 包含一个 IDR 帧到下一个 IDR 帧的前一帧中的所有帧。GOP 的大小选择需要根据实际应用场景来选择，一般 RTC 和直播场景可以稍微大一些，而点播场景一般小一些。

在 H264 中，每一帧图像又可以分为 I 帧、P 帧和 B 帧，而 I 帧又包含了普通 I 帧和 IDR 帧。帧可以划分为一个或者多个 Slice，并且最后帧都是以 Slice 的方式在码流中呈现。同时 H264 码流中除了 Slice 数据之外，还有 SPS 和 PPS 两个参数集，分别用来存放基础图像信息和基础编码参数。SPS 和 PPS 非常重要，如果丢失了，将无法进行解码。

每一个 Slice 和 SPS、PPS 都是通过 NALU 来封装的，且 NALU 含有一个 1 字节的 NALU Header。我们可以通过 NALU Header 中的 NALU Type 来判断 NALU 的类型。同时，每一个 NALU 的分隔有两种方式：一种是 Annexb 格式，通过使用起始码分隔；一种是 MP4 格式，通过一个 4 字节的长度来表示 NALU 的大小，从而起到分隔的作用。

为了帮助你记忆，我们通过下图来总结一下。

![H264码流结构](H264码流结构.webp)

# 06｜帧内预测：如何减少空间冗余？

